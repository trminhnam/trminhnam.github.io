---
---

@inproceedings{tran-etal-2024-viglue,
  abbr            = {ViGLUE},
  title           = {{V}i{GLUE}: A {V}ietnamese General Language Understanding Benchmark and Analysis of {V}ietnamese Language Models},
  author          = {Tran, Minh-Nam  and
                     Nguyen, Phu-Vinh  and
                     Nguyen, Long  and
                     Dinh, Dien},
  editor          = {Duh, Kevin  and
                     Gomez, Helena  and
                     Bethard, Steven},
  booktitle       = {Findings of the Association for Computational Linguistics: NAACL 2024},
  month           = jun,
  year            = {2024},
  address         = {Mexico City, Mexico},
  publisher       = {Association for Computational Linguistics},
  url             = {https://aclanthology.org/2024.findings-naacl.261},
  pages           = {4174--4189},
  pdf             = {https://aclanthology.org/2024.findings-naacl.261.pdf},
  code            = {https://github.com/trminhnam/ViGLUE},
  selected        = {true},
  additional_info = {. The dataset is available at [this link](https://huggingface.co/datasets/tmnam20/ViGLUE)},
  abstract        = {As the number of language models has increased, various benchmarks have been suggested to assess the proficiency of the models in natural language understanding. However, there is a lack of such a benchmark in Vietnamese due to the difficulty in accessing natural language processing datasets or the scarcity of task-specific datasets. *ViGLUE*, the proposed dataset collection, is a Vietnamese General Language Understanding Evaluation benchmark developed using three methods: translating an existing benchmark, generating new corpora, and collecting available datasets. ViGLUE contains twelve tasks and encompasses over ten areas and subjects, enabling it to evaluate models comprehensively over a broad spectrum of aspects. Baseline models utilizing multilingual language models are also provided for all tasks in the proposed benchmarks. In addition, the study of the available Vietnamese large language models is conducted to explore the language models{'} ability in the few-shot learning framework, leading to the exploration of the relationship between specific tasks and the number of shots.}
}
